---
title: "EDA"
author: "Samantha Hunter"
date: "10/17/2021"
output: html_document
---

# ``


```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, echo = TRUE, message = FALSE, warning = FALSE, error = TRUE)
```


# Introduction


The following space is reserved for the introduction. 
(sam - I think we should include info about how there is just bad data - articles that are indicated they should be empty, but aren't. The timedelta variable shows that we took the number of shares from articles published years ago up to two weeks before end) - this info is the only reason I haven't deleted the EDA on the entire data set yet. 



This is a report about which model to use when trying to predict the number of social media shares of an article with a topic of, (insert topic here), based on a myriad of predictors.

The data to build this report originally comes from [Mashable](mashable.com), and includes a variety of data about articles on their site during a two year period. Some of the data in this dataset are things like, the topic of the article, how long the article is, what day of the week the article was published on, how long ago it was published and a variety of other things.


To read more about all of the data included in the dataset read [here](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity). 


In this report we make models that include some of the predictor variables and others that include all of the predictor variables. The variables we specifically selected are shown below with their definitions:  

* `LDA_02` - closeness to LDA Topic 2.  
* `LDA_03` - closeness to LDA Topic 3.  
* `num_imgs` - Number of Images in an article.  
* `kw_avg_avg` -  Avg. keyword (avg. shares).  
* `n_tokens_content` - Number of words in the article.  
* `average_token_length` - Average length of words in the article.  
* `rate_negative_words` - Rate of positive words in the article.  
* `rate_negative_words` - Rate of negative words in the article.  
* `day` - A variable we create to signify what day of the week an article was published.  
* `kw_max_avg` - Avg. keyword (max. shares).  
* `title_subjectivity` - The subjectivity of the title of the article.


In this report we create the following models:  

* A Linear Model with all predictor variables.  
* A Linear Model with some selected predictor variables.  
* A Boosted Tree Model with all predictor variables.  
* A Boosted Tree Model with some selected predictor variables.  
* A Random Forest Model with...

At the end of this report we decide on which model was the best for the (topic).


The packages used in this report are:


```{r}
library(tidyverse)
library(caret)
library(rmarkdown)

# used for randomForests before I run on CV
library(randomForest)

# use this for parallel computing
library(parallel)
# also for parallel computing. I will look to see if it's the same later
library(doParallel)

# To use Kable for good looking data print out
library(knitr)

# For boosted tree
library(gbm)
```



### Reading in the data

# Data Processing

Below we read in the data, add new variables, remove old ones, filter specifically for (topic), and then we go ahead and split the data into the test and train data sets for model training and testing. 


```{r message = FALSE, echo=FALSE}
# read in raw data
data <- read_csv("OnlineNewsPopularity.csv")

# add in day of week variable called "day"
# check every indicator variable for a 1, once it hits a 1
# the new variable day is defined as whatever day it is
# if no 1 are present saves the day variable as "error".

# This same process takes place with topic.
data <- data %>%
  mutate(
    day = if_else(weekday_is_monday == 1, "monday",
                  if_else(weekday_is_tuesday == 1, "tuesday",
                          if_else(weekday_is_wednesday == 1, "wednesday",
                                  if_else(weekday_is_thursday == 1, "thursday",
                                          if_else(weekday_is_friday == 1, "friday",
                                                  if_else(weekday_is_saturday == 1, "saturday",
                                                          if_else(weekday_is_sunday == 1, "sunday","error"))))))),
    topic = if_else(data_channel_is_lifestyle == 1, "lifestyle", 
                  if_else(data_channel_is_entertainment == 1, "entertainment", 
                          if_else(data_channel_is_bus == 1, "business", 
                                  if_else(data_channel_is_socmed == 1, "socialMedia", 
                                          if_else(data_channel_is_tech == 1, "tech",
                                                  if_else(data_channel_is_world == 1, "world", "other"))))))
    )

# remove old day and topic indicators
data <- data %>%
  select(!starts_with("weekday_is_"), -starts_with("data_channel_is_"))

# change to factor
data$day <- as.factor(data$day)
data$topic <- as.factor(data$topic)


#check structure to make sure is successful 
str(data)

#double check for "errors"
table(data$day)
table(data$topic)

# these actually don't have a topic!
err <- data %>% filter(topic == "other")
```


### Subsetting Data 

```{r}
filtered_data <- data %>% filter(topic == params$topics) %>% select(!topic, -url)

set.seed(214)

# Splitting Data set into a 70% training set and 30% for a testing set 
train <- sample(1:nrow(filtered_data), size = nrow(filtered_data)*0.7)
test <- setdiff(1:nrow(filtered_data), train)

# Subsetting the data based on our split
train_set <- filtered_data[train, 1:48]
test_set  <- filtered_data[test, ]

# Log transformation used for one of the linear regression models:
train_log <- train_set %>% mutate(shares = log(shares))
test_log <- test_set %>% mutate(shares = log(shares))
```



# EDA - 


**NOTE: I combined our EDAs. I though it would be nice to go from a general exploration of the data, to the more specific qualities of the data and predictors.-Sam**


We can start by looking at the general qualities of the response variable, number of shares, for this data set. It's pretty clear that we have heavily right-skewed data. For example, the boxplot of `r params$topics`'s `shares` shows that we can't interpret a majority of the data due to the number of high-value outliers. To better visualize the population, we applied a log transformation to the response variable. We will also use the log-transformed data once more in one of the linear regression models. The log transformation works well with this data because number of shares is always positive and it is heavily right skewed. 
